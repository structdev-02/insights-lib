{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "import googlemaps\n",
    "from datetime import datetime\n",
    "import time \n",
    "\n",
    "gmaps = googlemaps.Client(key=os.getenv(\"GOOGLE_KEY\"))\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data enrichment\n",
    "\n",
    "This notebook handles the enrichment of the dataset by retrieving additional information from external APIs.\n",
    "\n",
    "The main steps include:\n",
    "\n",
    "- **Gender Imputation**: Uses the OpenAI API to infer missing customer genders based on their first names.\n",
    "- **Customer Address Enrichment**: Uses the Google Maps API to retrieve full address information for customers based on partial address data.\n",
    "- **Library Address Enrichment**: Applies the same address enrichment process to libraries using the Google Maps API.\n",
    "- **Distance Calculation**: Calculates driving distance between each customer and their associated library using the Google Maps Distance Matrix API.\n",
    "- **Weather Data Retrieval**: Fetches daily weather data (temperature, precipitation, snow) for the years 2018 and 2019 using the Meteostat API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get gender for missing entries in customer table\n",
    "\n",
    "This code section requires opnai client and api key (requires openai credits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male - Ronald Cedillo\n",
      "female - Stacy Dangelo\n",
      "male - William  Barrera \n",
      "male - Matthew Majszak\n",
      "female - Mary Riggs\n",
      "female - Maria Morris\n",
      "female - PAMELA THOMAS\n",
      "male - Donald Duran\n",
      "female - Angela Dipaolo\n",
      "male - Kevin Fuentes\n",
      "female - Elizabeth Lugo\n",
      "male - James Villacres\n",
      "male - Joel Riordan\n",
      "female - Debra Stephens\n",
      "female - Earnestine Bothe\n",
      "male - Jeffrey Matusz\n",
      "male - Robert Weber\n",
      "female - Elisa Venn\n",
      "male - John Sandoval\n",
      "female - Florence Rhoads\n",
      "female - christina GOMEZ\n",
      "male - Christopher Bohland\n",
      "female - Angle Taub\n",
      "male - Sam Summers\n",
      "male - Ricky Husky\n",
      "female - Beatrice Murphy\n",
      "male - Luke Malmquist\n",
      "male - Vince Farrell\n",
      "male - Douglas Johnson\n",
      "male - Willie Fairchild\n",
      "male - Gonzalo Cox\n",
      "female - Edith Johna\n",
      "female - Joline Carraro\n",
      "female - Wendy Gonzalez\n",
      "female - Ellen Osborne\n",
      "female - Ruth Dickes\n",
      "female - Kaylene Dunn\n",
      "female - Kasie Rodriguez\n",
      "male - Frank Parker\n",
      "female - Darlene Gridley\n",
      "male - Jeffrey Cabriales\n",
      "female - Sandra Franklin\n",
      "female - Mercedes Deniz\n",
      "female -  Ernestine Pederson \n",
      "male - Alexander Smith\n",
      "female - Lori Woody\n",
      "male - Richard Rangaswamy\n",
      "male - Richard Thomas\n",
      "female - MELLISSA Riley\n",
      "male - Alex Davis\n",
      "female - Marguerite Mackie\n",
      "female - Tricia Rodrigues\n",
      "female - Audrey Orozco\n",
      "female - Victoria Reyes\n",
      "male - George Howard\n",
      "female - Josie Burnett\n",
      "male - Leon Foust\n",
      "female - Cathy June\n",
      "female - Barbara Albers\n",
      "male - John Beattie\n",
      "female - Anna Culbertson\n",
      "female - Barbara Anderson\n",
      "male - George Harris\n",
      "female - Patricia Echelberger\n",
      "male - WILLIAM WATTERS\n",
      "female - Cheryl   Porter\n",
      "male -  Alan  Cornelius\n",
      "female - Frances Wortham\n",
      "female - Staci Brown\n",
      "female - Billie Barnes\n",
      "female - Lorena Corneau\n",
      "male - Bill Dias\n",
      "female - Eva  Holmes\n",
      "male - Louis Morris\n",
      "female - Elizebeth Lugo\n",
      "male - Nigel Haynes\n",
      "male - Jason Watts\n",
      "female - Stephanie Mathieu\n",
      "female - Margie Hebert\n",
      "female - Beth Stanley\n",
      "female - Laura Kuta\n",
      "female - Katie Gori\n",
      "male - Jose Lee\n",
      "female - Edna  Kimling \n",
      "female - Lisa Newman\n",
      "female - Marie Zaluski\n",
      "male - Adam Bodily\n",
      "male - Donald Butler\n",
      "male - Frank Weatherspoon\n",
      "female - Charline Tannous\n",
      "female - Ella Wood\n",
      "male - Marcus Jama\n",
      "female - Keisha Flores\n",
      "male - Daniel Person\n",
      "female - Judy Pavlich\n",
      "female - Judith Wilner\n",
      "female - Joan Walker\n",
      "male - Alejandro Burrell\n",
      "female - Karen Pingry\n",
      "male - Peter Phillipp\n",
      "female - Emilia Tubolino\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "file_path = 'data/customers.csv'\n",
    "customers_df = pd.read_csv(file_path, index_col='id')\n",
    "\n",
    "# Get slice of dataframe with missing entries\n",
    "missing_gender_df = customers_df[customers_df['gender'].isna()]\n",
    "missing_gender_df.head()\n",
    "\n",
    "# Get openAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPEN_API_KEY\"))\n",
    "\n",
    "# Function that inffers gender based on name\n",
    "def get_gender(name: str) -> str:\n",
    "    prompt = f\"Is the name '{name}' typically male or female? Always answer with 'male' or 'female'. Never ourput anything else but 'male' or 'female'\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip().lower()\n",
    "\n",
    "# Map names to genders for missing entires\n",
    "map_dict = {}\n",
    "\n",
    "for idx, row in missing_gender_df.iterrows():\n",
    "    \n",
    "    customer_id = idx\n",
    "    customer_name = row['name']\n",
    "    \n",
    "    map_dict[customer_id] = get_gender(customer_name)\n",
    "    print(f'{map_dict[customer_id]} - {customer_name}')\n",
    "    \n",
    "# Save results to mapping file\n",
    "with open(\"new_data/gender_map.json\", \"w\") as file:\n",
    "    json.dump(map_dict, file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get location data for customers\n",
    "\n",
    "Uses Google Cloud's Maps API client to retrieve the full address for each client based on available data.\n",
    "\n",
    "Requires a valid Google Maps API key.\n",
    "\n",
    "Note: To use the Google Maps API, you must have a Google Cloud account with billing enabled. (first 10k api calls are free)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progess 0 / 2000\n",
      "Progess 100 / 2000\n",
      "Progess 200 / 2000\n",
      "Progess 300 / 2000\n",
      "Progess 400 / 2000\n",
      "Progess 500 / 2000\n",
      "Progess 600 / 2000\n",
      "Progess 700 / 2000\n",
      "Progess 800 / 2000\n",
      "Progess 900 / 2000\n",
      "Progess 1000 / 2000\n",
      "Progess 1100 / 2000\n",
      "Progess 1200 / 2000\n",
      "Progess 1300 / 2000\n",
      "Progess 1400 / 2000\n",
      "Progess 1500 / 2000\n",
      "Progess 1600 / 2000\n",
      "Progess 1700 / 2000\n",
      "Progess 1800 / 2000\n",
      "Progess 1900 / 2000\n"
     ]
    }
   ],
   "source": [
    "file_path = 'data/customers.csv'\n",
    "customers_df = pd.read_csv(file_path, index_col='id')\n",
    "\n",
    "for count, idx in enumerate(customers_df.index):\n",
    "    \n",
    "    # Get google maps query by using provided adress, city and state\n",
    "    adress = customers_df.loc[idx, 'street_address']\n",
    "    \n",
    "    if not pd.isna(customers_df.loc[idx, 'city']):\n",
    "        adress = adress + ' ' + customers_df.loc[idx, 'city']\n",
    "    else:\n",
    "        adress = adress + ' ' + 'Portland' # using portland if city is missing since portland is most frequent\n",
    "    if not pd.isna(customers_df.loc[idx, 'state']):\n",
    "        adress = adress + ' ' + customers_df.loc[idx, 'state']\n",
    "        \n",
    "    # Query google maps\n",
    "    geo_result = gmaps.geocode(adress)\n",
    "\n",
    "    # Get formatted full adress, latitude and longitude\n",
    "    customers_df.loc[idx, 'full_adress'] = geo_result[0]['formatted_address']\n",
    "    customers_df.loc[idx, 'latitude'] = geo_result[0]['geometry']['location']['lat']\n",
    "    customers_df.loc[idx, 'longitude'] = geo_result[0]['geometry']['location']['lng']\n",
    "    \n",
    "    # Sleep in order not to exceed allowed rate limit\n",
    "    time.sleep(0.05)\n",
    "    \n",
    "    # Print progress\n",
    "    if count % 100 == 0:\n",
    "        print(f'Progess {count} / {customers_df.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save customer geo data\n",
    "customers_adress_df = customers_df[['full_adress', 'latitude', 'longitude']]\n",
    "customers_adress_df.to_csv('new_data/customer_location_map.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get location data for libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progess 0 / 18\n"
     ]
    }
   ],
   "source": [
    "# Get full adress data for each library based on provided adress and library name\n",
    "\n",
    "file_path = 'data/libraries.csv'\n",
    "libraries_df = pd.read_csv(file_path, index_col='id')\n",
    "\n",
    "for count, idx in enumerate(libraries_df.index):\n",
    "    \n",
    "    query = libraries_df.loc[idx, 'name'] + ' ' + libraries_df.loc[idx, 'street_address']\n",
    "    if not pd.isna(libraries_df.loc[idx, 'city']):\n",
    "        query = query + ' ' + libraries_df.loc[idx, 'city']\n",
    "            \n",
    "    geo_result = gmaps.geocode(query)\n",
    "\n",
    "    libraries_df.loc[idx, 'full_adress'] = geo_result[0]['formatted_address']\n",
    "    libraries_df.loc[idx, 'latitude'] = geo_result[0]['geometry']['location']['lat']\n",
    "    libraries_df.loc[idx, 'longitude'] = geo_result[0]['geometry']['location']['lng']\n",
    "    time.sleep(0.05)\n",
    "    \n",
    "    if count % 100 == 0:\n",
    "        print(f'Progess {count} / {libraries_df.shape[0]}')\n",
    "        \n",
    "# Save library with added data\n",
    "libraries_df.to_csv('data_preprocessed/libraries_with_geo.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate distances between customers and libraries\n",
    "\n",
    "Join checkouts, customers, and libraries to obtain both customer and library addresses in a single dataset.\n",
    "\n",
    "These addresses are used to calculate driving distance between each customer and their library.\n",
    "\n",
    "Driving distance is chosen as a proxy, as it also reflects general accessibility via walking or public transport.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge tables\n",
    "\n",
    "file_path = 'data/checkouts.csv'\n",
    "checkouts_df = pd.read_csv(file_path)\n",
    "\n",
    "checkouts_df = checkouts_df.join(\n",
    "    customers_adress_df.add_prefix('cust_'), \n",
    "    on=\"patron_id\", \n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "checkouts_df = checkouts_df.join(\n",
    "    libraries_df[['full_adress']].add_prefix('lib_'), \n",
    "    on=\"library_id\", \n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progess 0 / 2000\n",
      "Progess 100 / 2000\n",
      "Progess 200 / 2000\n",
      "Progess 300 / 2000\n",
      "Progess 400 / 2000\n",
      "Progess 500 / 2000\n",
      "Progess 600 / 2000\n",
      "Progess 700 / 2000\n",
      "Progess 800 / 2000\n",
      "Progess 900 / 2000\n",
      "Progess 1000 / 2000\n",
      "Progess 1100 / 2000\n",
      "Progess 1200 / 2000\n",
      "Progess 1300 / 2000\n",
      "Progess 1400 / 2000\n",
      "Progess 1500 / 2000\n",
      "Progess 1600 / 2000\n",
      "Progess 1700 / 2000\n",
      "Progess 1800 / 2000\n",
      "Progess 1900 / 2000\n"
     ]
    }
   ],
   "source": [
    "# Iterate dataframe rows\n",
    "# For each row, get driving distance and duration by using google maps matrxi api\n",
    "\n",
    "distance_dict = {}\n",
    "\n",
    "for idx, row in checkouts_df.iterrows():\n",
    "    \n",
    "    gmap_dist = gmaps.distance_matrix(\n",
    "        origins=[row['cust_full_adress']],\n",
    "        destinations=[row['lib_full_adress']],\n",
    "        mode='driving',\n",
    "        units='metric'\n",
    "    )\n",
    "    \n",
    "    distance = gmap_dist['rows'][0]['elements'][0]['distance']['value']/1000\n",
    "    duration = gmap_dist['rows'][0]['elements'][0]['duration']['value']/3600\n",
    "    \n",
    "    distance_dict[idx] = {\n",
    "        'customer_id': row['patron_id'],\n",
    "        'library_id': row['library_id'],\n",
    "        'distance': distance,\n",
    "        'duration': duration\n",
    "    }\n",
    "    time.sleep(0.05)\n",
    "    \n",
    "    if idx % 100 == 0:\n",
    "        print(f'Progess {idx} / {checkouts_df.shape[0]}')\n",
    "        \n",
    "cust_lib_distance_df = pd.DataFrame.from_dict(distance_dict, orient='index')\n",
    "cust_lib_distance_df.to_csv('new_data/lib_cust_dist.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get weather data\n",
    "\n",
    "Weather data for Portland was obtained via meteostat library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meteostat import Point, Daily\n",
    "from datetime import datetime\n",
    "\n",
    "# Define location (e.g., Portland, OR)\n",
    "location = Point(45.5152, -122.6784)  # lat, lon\n",
    "\n",
    "# Define date range\n",
    "start = datetime(2018, 1, 1)\n",
    "end = datetime(2020, 1, 1)\n",
    "\n",
    "# Get daily data\n",
    "weather_data = Daily(location, start, end)\n",
    "weather_data = weather_data.fetch()\n",
    "\n",
    "weather_data.reset_index().to_csv('data_preprocessed/weather_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "snow\n",
       "0.0     724\n",
       "80.0      3\n",
       "30.0      2\n",
       "50.0      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data['snow'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insights-lib--knkMJpa-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
